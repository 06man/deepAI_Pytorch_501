{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-17T05:32:52.173173Z",
     "start_time": "2025-03-17T05:32:52.152725Z"
    }
   },
   "source": [
    "#파이토치 기본 라이브러리\n",
    "import torch\n",
    "\n",
    "# 이미지와 관련된 파이토치 라이브러리\n",
    "import torchvision\n",
    "\n",
    "#이미지 전처리 기능들을 제공하는 라이브러리\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "#데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as p\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T05:32:52.189168Z",
     "start_time": "2025-03-17T05:32:52.179147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# tr.Compose 내에 원하는 전처리를 차례대로 넣어주면 된다.\n",
    "\n",
    "transf = tr.Compose([tr.Resize(16),tr.ToTensor()]) # 16x16으로 이미지 크기 변환 후 텐서 타입으로 변환한다.\n",
    "\n",
    "# torchvision.datasets에서 제공하는 CIFAR10 데이터를 불러온다.\n",
    "# root에는 다운로드 받을 경로를 입력한다.\n",
    "# train=Ture이면 학습 데이터를 불러오고 train=False이면 테스트 데이터를 불러온다.\n",
    "# 미리 선언한 전처리를 사용하기 위해 transform=transf을 입력한다.\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)\n",
    "# 커스텀 데이터 불러온다.\n",
    "trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf)\n"
   ],
   "id": "5f43de0b78a9b520",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T05:32:52.330331Z",
     "start_time": "2025-03-17T05:32:52.207146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 일반적으로 데이터셋은 이미지와 라벨이 동시에 들어있는 튜플(tuple) 형태다.\n",
    "# (이미지, 라벨)\n",
    "# trainset[0]은 학습 데이터의 첫 번째 데이터로\n",
    "# 이미지 한 장과 라벨 숫자 하나가 저장되어 있다.\n",
    "# 즉, trainset[0][0]은 이미지이며 trainset[0][1]은 라벨이다.\n",
    "\n",
    "print(trainset[0][0].size())\n",
    "\n",
    "# 현재 이미지 사이즈는 3x16x16이다. 여기서 3은 채널 수를 말하고\n",
    "# 16x16은 이미지의 너비와 높이를 의미한다.\n",
    "# 일반적인 컬러 사진은 RGB 이미지이기 때문에 채널이 3개 이고\n",
    "# (너비)x(높이)x(채널 수)로 크기가 표현된다.\n",
    "\n",
    "# 하지만 파이토치에서는 이미지 한 장이 (채널 수)x(너비)x(높이)으로\n",
    "# 표현되니 유의하도록 한다.\n",
    "\n",
    "# DataLoader는 데이터를 미니 배치 형태로 만들어 준다.\n",
    "# 따라서 배치 사이즈 및 셔플 여부 등을 선택할 수 있다.\n",
    "trainloader = DataLoader(trainset, batch_size=50, shuffle=True)\n",
    "# testloader = DataLoader(testset, batch_size=50, shuffle=False)\n",
    "\n",
    "# 즉, batch_size=50, shuffle=True은\n",
    "# 무작위로 데이터를 섞어 한 번 에 50개의 이미지를 묶은 배치로 제공하겠다는 의미다.\n",
    "\n",
    "# len(trainloader)\n",
    "# Output: 1000\n",
    "#\n",
    "# CIFAR10의 학습 이미지는 50000장이고 배치 사이즈가 50장이므로\n",
    "# 1000은 배치의 개수가 된다.\n",
    "\n",
    "# Output: torch.Size([50, 3, 16, 16)\n",
    "#\n",
    "# 배치 이미지를 간단히 확인하기 위해 파이썬에서 제공하는\n",
    "# iter와 next 함수를 이용한다.\n",
    "#\n",
    "# 이를 통 해 trainloader의 첫 번째 배치를 불러올 수 있다.\n",
    "# 1 배치 사이즈는 (배치 크기)×(채널 수)×(너비) (높이)를 의미한다.\n",
    "# 즉, 배치 하나에 이미지 50개가 잘 들어가 있음을 알 수 있다.\n",
    "#\n",
    "\n",
    "# iter, next를 이용해 일부 데이터를 확인할 수 있다.\n",
    "images, labels = next(iter(trainloader))\n",
    "print(images.size())\n",
    "\n",
    "# 일반적으로 학습 데이터는 4차원 형태로 모델에서 사용된다.\n",
    "# (배치 크기)x(채널 수)x(너비)x(높이)\n",
    "# torch.Size([50, 3, 16, 16])\n",
    "oneshot = images[1].permute(1,2,0).numpy()\n",
    "print(oneshot.size())\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(oneshot)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "id": "32882dc56fa805e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 18, 16] at entry 0 and [3, 16, 16] at entry 4",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 42\u001B[0m\n\u001B[0;32m     19\u001B[0m trainloader \u001B[38;5;241m=\u001B[39m DataLoader(trainset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# testloader = DataLoader(testset, batch_size=50, shuffle=False)\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# 즉, batch_size=50, shuffle=True은\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     40\u001B[0m \n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# iter, next를 이용해 일부 데이터를 확인할 수 있다.\u001B[39;00m\n\u001B[1;32m---> 42\u001B[0m images, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrainloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28mprint\u001B[39m(images\u001B[38;5;241m.\u001B[39msize())\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# 일반적으로 학습 데이터는 4차원 형태로 모델에서 사용된다.\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# (배치 크기)x(채널 수)x(너비)x(높이)\u001B[39;00m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# torch.Size([50, 3, 16, 16])\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 708\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    709\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    710\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    714\u001B[0m ):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    762\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    763\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 764\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    765\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    766\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[1;32m---> 55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001B[0m, in \u001B[0;36mdefault_collate\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m    337\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[0;32m    338\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[0;32m    340\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    396\u001B[0m \u001B[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[0;32m    397\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 398\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:211\u001B[0m, in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    208\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m    212\u001B[0m         collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map)\n\u001B[0;32m    213\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed\n\u001B[0;32m    214\u001B[0m     ]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    208\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m--> 212\u001B[0m         \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    213\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed\n\u001B[0;32m    214\u001B[0m     ]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001B[0m, in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m collate_fn_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    154\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m elem_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[1;32m--> 155\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43melem_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[0;32m    158\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001B[0m, in \u001B[0;36mcollate_tensor_fn\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    270\u001B[0m     storage \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39m_typed_storage()\u001B[38;5;241m.\u001B[39m_new_shared(numel, device\u001B[38;5;241m=\u001B[39melem\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    271\u001B[0m     out \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39mnew(storage)\u001B[38;5;241m.\u001B[39mresize_(\u001B[38;5;28mlen\u001B[39m(batch), \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlist\u001B[39m(elem\u001B[38;5;241m.\u001B[39msize()))\n\u001B[1;32m--> 272\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: stack expects each tensor to be equal size, but got [3, 18, 16] at entry 0 and [3, 16, 16] at entry 4"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9fbab4b5b98d05ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f5dc6f8c4c2f02a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1ce673d79ee622df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
